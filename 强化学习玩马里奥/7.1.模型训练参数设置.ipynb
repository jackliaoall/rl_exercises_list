{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ebbb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "\n",
    "monitor_dir = r'./monitor_log/'\n",
    "os.makedirs(monitor_dir,exist_ok=True)\n",
    "env = Monitor(env,monitor_dir)\n",
    "\n",
    "env = GrayScaleObservation(env,keep_dim=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env,4,channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fab5b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "#1.直接設置參數\n",
    "tensorboard_log = r'./tensorboard_log/'\n",
    "# learning_rate\n",
    "# n_steps\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1,\n",
    "            tensorboard_log = tensorboard_log)\n",
    "# model.learn(total_timesteps=25000)\n",
    "# model.save(\"mario_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d31d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_current_progress_remaining',\n",
       " '_custom_logger',\n",
       " '_episode_num',\n",
       " '_excluded_save_params',\n",
       " '_get_eval_env',\n",
       " '_get_torch_save_params',\n",
       " '_init_callback',\n",
       " '_last_episode_starts',\n",
       " '_last_obs',\n",
       " '_last_original_obs',\n",
       " '_logger',\n",
       " '_n_updates',\n",
       " '_num_timesteps_at_start',\n",
       " '_setup_learn',\n",
       " '_setup_lr_schedule',\n",
       " '_setup_model',\n",
       " '_total_timesteps',\n",
       " '_update_current_progress_remaining',\n",
       " '_update_info_buffer',\n",
       " '_update_learning_rate',\n",
       " '_vec_normalize_env',\n",
       " '_wrap_env',\n",
       " 'action_noise',\n",
       " 'action_space',\n",
       " 'batch_size',\n",
       " 'clip_range',\n",
       " 'clip_range_vf',\n",
       " 'collect_rollouts',\n",
       " 'device',\n",
       " 'ent_coef',\n",
       " 'env',\n",
       " 'ep_info_buffer',\n",
       " 'ep_success_buffer',\n",
       " 'eval_env',\n",
       " 'gae_lambda',\n",
       " 'gamma',\n",
       " 'get_env',\n",
       " 'get_parameters',\n",
       " 'get_vec_normalize_env',\n",
       " 'learn',\n",
       " 'learning_rate',\n",
       " 'load',\n",
       " 'logger',\n",
       " 'lr_schedule',\n",
       " 'max_grad_norm',\n",
       " 'n_envs',\n",
       " 'n_epochs',\n",
       " 'n_steps',\n",
       " 'normalize_advantage',\n",
       " 'num_timesteps',\n",
       " 'observation_space',\n",
       " 'policy',\n",
       " 'policy_class',\n",
       " 'policy_kwargs',\n",
       " 'predict',\n",
       " 'rollout_buffer',\n",
       " 'save',\n",
       " 'sde_sample_freq',\n",
       " 'seed',\n",
       " 'set_env',\n",
       " 'set_logger',\n",
       " 'set_parameters',\n",
       " 'set_random_seed',\n",
       " 'start_time',\n",
       " 'target_kl',\n",
       " 'tensorboard_log',\n",
       " 'train',\n",
       " 'use_sde',\n",
       " 'verbose',\n",
       " 'vf_coef']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84cf6e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "print(model.learning_rate)\n",
    "print(model.n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e052dc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "tensorboard_log = r'./tensorboard_log/'\n",
    "learning_rate = 1e-6\n",
    "n_steps = 128\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1,\n",
    "            tensorboard_log = tensorboard_log,\n",
    "            learning_rate = learning_rate,\n",
    "            n_steps = n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b071f9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "print(model.learning_rate)\n",
    "print(model.n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6608f364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "1e-08\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "#2.通過字典設置參數\n",
    "model_param_1={\n",
    "    'learning_rate' : 1e-8,\n",
    "    'n_steps' : 1024\n",
    "}\n",
    "\n",
    "tensorboard_log = r'./tensorboard_log/'\n",
    "\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1,\n",
    "            tensorboard_log = tensorboard_log,\n",
    "            **model_param_1)\n",
    "\n",
    "print(model.learning_rate)\n",
    "print(model.n_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
